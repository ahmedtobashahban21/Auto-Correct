{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8d6c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:51.673366Z",
     "iopub.status.busy": "2023-07-29T15:19:51.672918Z",
     "iopub.status.idle": "2023-07-29T15:19:51.684603Z",
     "shell.execute_reply": "2023-07-29T15:19:51.683704Z"
    },
    "papermill": {
     "duration": 0.025541,
     "end_time": "2023-07-29T15:19:51.686803",
     "exception": false,
     "start_time": "2023-07-29T15:19:51.661262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_link = '/kaggle/input/auto-correct-dataset/auto_correct.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f54cb23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:51.707861Z",
     "iopub.status.busy": "2023-07-29T15:19:51.706662Z",
     "iopub.status.idle": "2023-07-29T15:19:54.091441Z",
     "shell.execute_reply": "2023-07-29T15:19:54.089989Z"
    },
    "papermill": {
     "duration": 2.398177,
     "end_time": "2023-07-29T15:19:54.094452",
     "exception": false,
     "start_time": "2023-07-29T15:19:51.696275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk \n",
    "import bs4 \n",
    "import re \n",
    "import string \n",
    "from collections import Counter \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306fea8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:54.115733Z",
     "iopub.status.busy": "2023-07-29T15:19:54.115030Z",
     "iopub.status.idle": "2023-07-29T15:19:54.999035Z",
     "shell.execute_reply": "2023-07-29T15:19:54.997633Z"
    },
    "papermill": {
     "duration": 0.897689,
     "end_time": "2023-07-29T15:19:55.001759",
     "exception": false,
     "start_time": "2023-07-29T15:19:54.104070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'the',\n",
       " '100th',\n",
       " 'etext',\n",
       " 'file',\n",
       " 'presented',\n",
       " 'by',\n",
       " 'project',\n",
       " 'gutenberg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's load our data \n",
    "# we have an artical, now we need to get all words in this artical in one list \n",
    "\n",
    "\n",
    "def load_words(data_file):\n",
    "    # create list to get all words \n",
    "    words =[]\n",
    "    with open(data_file ,'r') as file:\n",
    "        load_file = file.read()\n",
    "        # ignore all white space \n",
    "        process_file = re.findall(r'\\w+' , load_file)\n",
    "        for word in process_file :\n",
    "            words.append(word.lower())\n",
    "    return words \n",
    "\n",
    "\n",
    "# now let's load data \n",
    "\n",
    "data = load_words(data_link)\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0588c70f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.022706Z",
     "iopub.status.busy": "2023-07-29T15:19:55.022323Z",
     "iopub.status.idle": "2023-07-29T15:19:55.102582Z",
     "shell.execute_reply": "2023-07-29T15:19:55.101610Z"
    },
    "papermill": {
     "duration": 0.093672,
     "end_time": "2023-07-29T15:19:55.105154",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.011482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words before: 929396\n",
      "number of words after: 23902\n",
      "number of repeated: 905494\n"
     ]
    }
   ],
   "source": [
    "# let's create our vocabular --> remove repeated words\n",
    "\n",
    "vocab = set(data)\n",
    "print(f'number of words before: {len(data)}')\n",
    "print(f'number of words after: {len(vocab)}')\n",
    "print(f'number of repeated: {len(data) - len(vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a990a",
   "metadata": {
    "papermill": {
     "duration": 0.009919,
     "end_time": "2023-07-29T15:19:55.125584",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.115665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style= \"background: #ea97ad; text-align:center\">Word Count </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0464891",
   "metadata": {
    "papermill": {
     "duration": 0.009322,
     "end_time": "2023-07-29T15:19:55.146020",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.136698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- we need to get counts of words to calculate probabilities of each word \n",
    "- let's get an example for what we get from get_count function \n",
    "\n",
    "| **Key** |**Value**|\n",
    "|---------|---------|\n",
    "| I       | 2       |\n",
    "| am      | 2       |\n",
    "|happy    | 1       |\n",
    "|running  | 1       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0f0d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.168416Z",
     "iopub.status.busy": "2023-07-29T15:19:55.167709Z",
     "iopub.status.idle": "2023-07-29T15:19:55.296241Z",
     "shell.execute_reply": "2023-07-29T15:19:55.295003Z"
    },
    "papermill": {
     "duration": 0.142186,
     "end_time": "2023-07-29T15:19:55.298697",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.156511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_count(word_list):\n",
    "    final_dict = dict()\n",
    "    final_dict = Counter(word_list)\n",
    "    return final_dict \n",
    "\n",
    "# let's get it now \n",
    "\n",
    "\n",
    "count_words = get_count(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d8ec98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.321006Z",
     "iopub.status.busy": "2023-07-29T15:19:55.320030Z",
     "iopub.status.idle": "2023-07-29T15:19:55.332326Z",
     "shell.execute_reply": "2023-07-29T15:19:55.331101Z"
    },
    "papermill": {
     "duration": 0.026418,
     "end_time": "2023-07-29T15:19:55.335119",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.308701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| key\tvalue\t|\n",
      "| ---\t-----\t|\n",
      "| this\t6853\t|\n",
      "| is\t9784\t|\n",
      "| the\t27660\t|\n",
      "| 100th\t1\t|\n",
      "| etext\t245\t|\n",
      "| file\t20\t|\n"
     ]
    }
   ],
   "source": [
    "print(f'| key\\tvalue\\t|')\n",
    "print(f'| ---\\t-----\\t|')\n",
    "for i in range(6):\n",
    "    get_keys =list( count_words.keys())\n",
    "    print(f'| {get_keys[i]}\\t{count_words[f\"{get_keys[i]}\"]}\\t|')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000e420",
   "metadata": {
    "papermill": {
     "duration": 0.009621,
     "end_time": "2023-07-29T15:19:55.354784",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.345163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style= \"background: #ea97ad; text-align:center\">Get Probability </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "553d6194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.376533Z",
     "iopub.status.busy": "2023-07-29T15:19:55.376152Z",
     "iopub.status.idle": "2023-07-29T15:19:55.392625Z",
     "shell.execute_reply": "2023-07-29T15:19:55.391425Z"
    },
    "papermill": {
     "duration": 0.030713,
     "end_time": "2023-07-29T15:19:55.395348",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.364635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now it's time for get probability to each word \n",
    "# now we have dictionary of {words: count }\n",
    "# and we have length of all words in artical to get probability of each of them.\n",
    "\n",
    "def get_proba(count_words):\n",
    "    proba_dict = dict()\n",
    "    total_words = sum(count_words.values())\n",
    "    for word , word_value in count_words.items():\n",
    "        proba_dict[word] = word_value / total_words \n",
    "    return proba_dict \n",
    "\n",
    "\n",
    "words_proba = get_proba(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc7c7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.417298Z",
     "iopub.status.busy": "2023-07-29T15:19:55.416870Z",
     "iopub.status.idle": "2023-07-29T15:19:55.428451Z",
     "shell.execute_reply": "2023-07-29T15:19:55.426806Z"
    },
    "papermill": {
     "duration": 0.026694,
     "end_time": "2023-07-29T15:19:55.432171",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.405477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| word\t|probability\t\t|\n",
      "| ------|-----------------------|\n",
      "| this\t|0.007373606083951298\t|\n",
      "| is\t|0.01052726717136721\t|\n",
      "| the\t|0.029761264304989477\t|\n",
      "| 100th\t|1.0759676176785783e-06\t|\n",
      "| etext\t|0.00026361206633125167\t|\n",
      "| file\t|2.1519352353571567e-05\t|\n"
     ]
    }
   ],
   "source": [
    "print(f'| word\\t|probability\\t\\t|')\n",
    "print(f'| ------|-----------------------|')\n",
    "for i in range(6):\n",
    "    get_keys =list( words_proba.keys())\n",
    "    print(f'| {get_keys[i]}\\t|{words_proba[f\"{get_keys[i]}\"]}\\t|')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a12bf",
   "metadata": {
    "papermill": {
     "duration": 0.009625,
     "end_time": "2023-07-29T15:19:55.452243",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.442618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background: #ea97ad;text-align:center\">Performing String Manipulations</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f740b",
   "metadata": {
    "papermill": {
     "duration": 0.009569,
     "end_time": "2023-07-29T15:19:55.471879",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.462310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, that we have computed $P(w_i)$ for all the words in the corpus, we will write a few functions to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words. In this section, we will implement four functions: \n",
    "\n",
    "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
    "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
    "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
    "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b20922ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.493904Z",
     "iopub.status.busy": "2023-07-29T15:19:55.493493Z",
     "iopub.status.idle": "2023-07-29T15:19:55.501413Z",
     "shell.execute_reply": "2023-07-29T15:19:55.500175Z"
    },
    "papermill": {
     "duration": 0.023554,
     "end_time": "2023-07-29T15:19:55.505231",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.481677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:cans\n",
      "split list: [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')]\n",
      "delete list: ['ans', 'cns', 'cas', 'can']\n"
     ]
    }
   ],
   "source": [
    "# let's start with delete_letter \n",
    "\n",
    "def delete_letter(word , verbos = False):\n",
    "    # to explain what will happen \n",
    "    # we just need two lists \n",
    "    # 1. split list ---> return a tuple of ( 'c' , 'ans') \n",
    "    # 2. delete list ---> return a word deleted one charater each time \n",
    "    \n",
    "    \n",
    "    split_list  = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    delete_list = [L+C[1:] for L,C in split_list]\n",
    "    \n",
    "    if verbos:\n",
    "        print(f'word:{word}\\nsplit list: {split_list}\\ndelete list: {delete_list}')\n",
    "    return delete_list \n",
    "\n",
    "\n",
    "# let's check our function \n",
    "\n",
    "get_items = delete_letter(word='cans' , verbos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1bf6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.530587Z",
     "iopub.status.busy": "2023-07-29T15:19:55.529742Z",
     "iopub.status.idle": "2023-07-29T15:19:55.537848Z",
     "shell.execute_reply": "2023-07-29T15:19:55.536816Z"
    },
    "papermill": {
     "duration": 0.023104,
     "end_time": "2023-07-29T15:19:55.540068",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.516964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: ate\n",
      "split list:[('', 'ate'), ('a', 'te'), ('at', 'e')]\n",
      "switching list: ['tae', 'aet']\n"
     ]
    }
   ],
   "source": [
    "# second function is switching \n",
    "\n",
    "def switching_letter(word , verbos= False):\n",
    "    \n",
    "    split_list = [(word[:i],word[i:]) for i in range(len(word))]\n",
    "\n",
    "    switch_list= [L+R[1]+R[0]+R[2:] for L,R in split_list  if len(R)>=2]\n",
    "    \n",
    "    if verbos :\n",
    "        print(f'word: {word}\\nsplit list:{split_list}\\nswitching list: {switch_list}')\n",
    "    return switch_list \n",
    "\n",
    "# let's check our function \n",
    "\n",
    "get_items = switching_letter(word='ate' , verbos = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1523fcff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.563163Z",
     "iopub.status.busy": "2023-07-29T15:19:55.562705Z",
     "iopub.status.idle": "2023-07-29T15:19:55.571373Z",
     "shell.execute_reply": "2023-07-29T15:19:55.570307Z"
    },
    "papermill": {
     "duration": 0.02422,
     "end_time": "2023-07-29T15:19:55.574651",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.550431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: can\n",
      "split list: [('', 'can'), ('c', 'an'), ('ca', 'n')]\n",
      "replace list: ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'can', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
     ]
    }
   ],
   "source": [
    "# replace operation \n",
    "\n",
    "def replace(word  , verbos = False):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    split_list  =[ (word[0:i] , word[i:]) for i in range(len(word))  ]\n",
    "    replace_list=[ L+ letter+(R[1:] if len(R)>1 else '') for L,R in split_list for letter in letters    ]\n",
    "    replace_list= sorted( set(replace_list))\n",
    "    if verbos:\n",
    "        print(f'word: {word}\\nsplit list: {split_list}\\nreplace list: {replace_list}')\n",
    "    return replace_list\n",
    "\n",
    "\n",
    "# let's test function \n",
    "get_items = replace(word='can' , verbos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f0e8ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.597835Z",
     "iopub.status.busy": "2023-07-29T15:19:55.597163Z",
     "iopub.status.idle": "2023-07-29T15:19:55.606175Z",
     "shell.execute_reply": "2023-07-29T15:19:55.604531Z"
    },
    "papermill": {
     "duration": 0.023877,
     "end_time": "2023-07-29T15:19:55.608952",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.585075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:at\n",
      "split list:[('', 'at'), ('a', 't'), ('at', '')]\n",
      "insert list:['aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat']\n"
     ]
    }
   ],
   "source": [
    "# let's do last functio \n",
    "\n",
    "def insert(word , verbos =False):\n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    split_list = [(word[:i] , word[i:]) for i in range(len(word)+1)]\n",
    "    insert_list= [L+ letter+R for L,R in split_list for letter in letters]\n",
    "    insert_list = sorted( set(insert_list)  )\n",
    "    if verbos:\n",
    "        print(f'word:{word}\\nsplit list:{split_list}\\ninsert list:{insert_list}')\n",
    "    return insert_list\n",
    "\n",
    "# let's check \n",
    "\n",
    "get_items  = insert(word='at' , verbos=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc100e6c",
   "metadata": {
    "papermill": {
     "duration": 0.010488,
     "end_time": "2023-07-29T15:19:55.629811",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.619323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"background: #ea97ad;text-align:center\">Edit One Letter</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c548a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.652599Z",
     "iopub.status.busy": "2023-07-29T15:19:55.652218Z",
     "iopub.status.idle": "2023-07-29T15:19:55.659244Z",
     "shell.execute_reply": "2023-07-29T15:19:55.657916Z"
    },
    "papermill": {
     "duration": 0.021304,
     "end_time": "2023-07-29T15:19:55.661765",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.640461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edit_one_letter(word , switch = True):\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    edit_one_set.update(delete_letter(word))\n",
    "    if switch:\n",
    "        edit_one_set.update(switching_letter(word))\n",
    "    edit_one_set.update(replace(word))\n",
    "    edit_one_set.update(insert(word))\n",
    "    if word in edit_one_set:\n",
    "        edit_one_set.remove(word)\n",
    "    return edit_one_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1b20c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.684895Z",
     "iopub.status.busy": "2023-07-29T15:19:55.684516Z",
     "iopub.status.idle": "2023-07-29T15:19:55.691138Z",
     "shell.execute_reply": "2023-07-29T15:19:55.689783Z"
    },
    "papermill": {
     "duration": 0.021812,
     "end_time": "2023-07-29T15:19:55.693881",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.672069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:at:\n",
      "edit one letter: ['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n"
     ]
    }
   ],
   "source": [
    "# let's check \n",
    "word = 'at'\n",
    "word_edit = edit_one_letter(word=word)\n",
    "listed = sorted( list(word_edit))\n",
    "\n",
    "\n",
    "print(f'word:{word}:\\nedit one letter: {listed}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8062597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.716427Z",
     "iopub.status.busy": "2023-07-29T15:19:55.716006Z",
     "iopub.status.idle": "2023-07-29T15:19:55.722527Z",
     "shell.execute_reply": "2023-07-29T15:19:55.721387Z"
    },
    "papermill": {
     "duration": 0.020682,
     "end_time": "2023-07-29T15:19:55.725139",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.704457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's do edit to letter \n",
    "\n",
    "\n",
    "def edit_two_letter(word , switch=True):\n",
    "    \n",
    "    edit_two_set =set()\n",
    "    edit_one = edit_one_letter(word , switch)\n",
    "    for W in edit_one:\n",
    "        edit_two = edit_one_letter(W,switch)\n",
    "        edit_two_set.update(edit_two)\n",
    "    return edit_two_set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ca9c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.747848Z",
     "iopub.status.busy": "2023-07-29T15:19:55.746987Z",
     "iopub.status.idle": "2023-07-29T15:19:55.762736Z",
     "shell.execute_reply": "2023-07-29T15:19:55.761396Z"
    },
    "papermill": {
     "duration": 0.030579,
     "end_time": "2023-07-29T15:19:55.765962",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.735383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:a\n",
      "Edit Two Letters:\n",
      "['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag', 'aah', 'aai', 'aaj', 'aak', 'aal', 'aam', 'aan', 'aao', 'aap', 'aaq', 'aar', 'aas', 'aat', 'aau', 'aav', 'aaw', 'aax', 'aay', 'aaz', 'ab', 'aba', 'abb', 'abc', 'abd', 'abe', 'abf', 'abg', 'abh', 'abi', 'abj', 'abk', 'abl', 'abm', 'abn', 'abo', 'abp', 'abq', 'abr', 'abs', 'abt', 'abu', 'abv', 'abw', 'abx', 'aby', 'abz', 'ac', 'aca', 'acb', 'acc', 'acd', 'ace', 'acf', 'acg', 'ach', 'aci', 'acj', 'ack', 'acl', 'acm', 'acn', 'aco', 'acp', 'acq', 'acr', 'acs', 'act', 'acu', 'acv', 'acw', 'acx', 'acy', 'acz', 'ad', 'ada', 'adb', 'adc', 'add', 'ade', 'adf', 'adg', 'adh', 'adi', 'adj', 'adk', 'adl', 'adm', 'adn', 'ado', 'adp', 'adq', 'adr', 'ads', 'adt', 'adu', 'adv', 'adw', 'adx', 'ady', 'adz', 'ae', 'aea', 'aeb', 'aec', 'aed', 'aee', 'aef', 'aeg', 'aeh', 'aei', 'aej', 'aek', 'ael', 'aem', 'aen', 'aeo', 'aep', 'aeq', 'aer', 'aes', 'aet', 'aeu', 'aev', 'aew', 'aex', 'aey', 'aez', 'af', 'afa', 'afb', 'afc', 'afd', 'afe', 'aff', 'afg', 'afh', 'afi', 'afj', 'afk', 'afl', 'afm', 'afn', 'afo', 'afp', 'afq', 'afr', 'afs', 'aft', 'afu', 'afv', 'afw', 'afx', 'afy', 'afz', 'ag', 'aga', 'agb', 'agc', 'agd', 'age', 'agf', 'agg', 'agh', 'agi', 'agj', 'agk', 'agl', 'agm', 'agn', 'ago', 'agp', 'agq', 'agr', 'ags', 'agt', 'agu', 'agv', 'agw', 'agx', 'agy', 'agz', 'ah', 'aha', 'ahb', 'ahc', 'ahd', 'ahe', 'ahf', 'ahg', 'ahh', 'ahi', 'ahj', 'ahk', 'ahl', 'ahm', 'ahn', 'aho', 'ahp', 'ahq', 'ahr', 'ahs', 'aht', 'ahu', 'ahv', 'ahw', 'ahx', 'ahy', 'ahz', 'ai', 'aia', 'aib', 'aic', 'aid', 'aie', 'aif', 'aig', 'aih', 'aii', 'aij', 'aik', 'ail', 'aim', 'ain', 'aio', 'aip', 'aiq', 'air', 'ais', 'ait', 'aiu', 'aiv', 'aiw', 'aix', 'aiy', 'aiz', 'aj', 'aja', 'ajb', 'ajc', 'ajd', 'aje', 'ajf', 'ajg', 'ajh', 'aji', 'ajj', 'ajk', 'ajl', 'ajm', 'ajn', 'ajo', 'ajp', 'ajq', 'ajr', 'ajs', 'ajt', 'aju', 'ajv', 'ajw', 'ajx', 'ajy', 'ajz', 'ak', 'aka', 'akb', 'akc', 'akd', 'ake', 'akf', 'akg', 'akh', 'aki', 'akj', 'akk', 'akl', 'akm', 'akn', 'ako', 'akp', 'akq', 'akr', 'aks', 'akt', 'aku', 'akv', 'akw', 'akx', 'aky', 'akz', 'al', 'ala', 'alb', 'alc', 'ald', 'ale', 'alf', 'alg', 'alh', 'ali', 'alj', 'alk', 'all', 'alm', 'aln', 'alo', 'alp', 'alq', 'alr', 'als', 'alt', 'alu', 'alv', 'alw', 'alx', 'aly', 'alz', 'am', 'ama', 'amb', 'amc', 'amd', 'ame', 'amf', 'amg', 'amh', 'ami', 'amj', 'amk', 'aml', 'amm', 'amn', 'amo', 'amp', 'amq', 'amr', 'ams', 'amt', 'amu', 'amv', 'amw', 'amx', 'amy', 'amz', 'an', 'ana', 'anb', 'anc', 'and', 'ane', 'anf', 'ang', 'anh', 'ani', 'anj', 'ank', 'anl', 'anm', 'ann', 'ano', 'anp', 'anq', 'anr', 'ans', 'ant', 'anu', 'anv', 'anw', 'anx', 'any', 'anz', 'ao', 'aoa', 'aob', 'aoc', 'aod', 'aoe', 'aof', 'aog', 'aoh', 'aoi', 'aoj', 'aok', 'aol', 'aom', 'aon', 'aoo', 'aop', 'aoq', 'aor', 'aos', 'aot', 'aou', 'aov', 'aow', 'aox', 'aoy', 'aoz', 'ap', 'apa', 'apb', 'apc', 'apd', 'ape', 'apf', 'apg', 'aph', 'api', 'apj', 'apk', 'apl', 'apm', 'apn', 'apo', 'app', 'apq', 'apr', 'aps', 'apt', 'apu', 'apv', 'apw', 'apx', 'apy', 'apz', 'aq', 'aqa', 'aqb', 'aqc', 'aqd', 'aqe', 'aqf', 'aqg', 'aqh', 'aqi', 'aqj', 'aqk', 'aql', 'aqm', 'aqn', 'aqo', 'aqp', 'aqq', 'aqr', 'aqs', 'aqt', 'aqu', 'aqv', 'aqw', 'aqx', 'aqy', 'aqz', 'ar', 'ara', 'arb', 'arc', 'ard', 'are', 'arf', 'arg', 'arh', 'ari', 'arj', 'ark', 'arl', 'arm', 'arn', 'aro', 'arp', 'arq', 'arr', 'ars', 'art', 'aru', 'arv', 'arw', 'arx', 'ary', 'arz', 'as', 'asa', 'asb', 'asc', 'asd', 'ase', 'asf', 'asg', 'ash', 'asi', 'asj', 'ask', 'asl', 'asm', 'asn', 'aso', 'asp', 'asq', 'asr', 'ass', 'ast', 'asu', 'asv', 'asw', 'asx', 'asy', 'asz', 'at', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aua', 'aub', 'auc', 'aud', 'aue', 'auf', 'aug', 'auh', 'aui', 'auj', 'auk', 'aul', 'aum', 'aun', 'auo', 'aup', 'auq', 'aur', 'aus', 'aut', 'auu', 'auv', 'auw', 'aux', 'auy', 'auz', 'av', 'ava', 'avb', 'avc', 'avd', 'ave', 'avf', 'avg', 'avh', 'avi', 'avj', 'avk', 'avl', 'avm', 'avn', 'avo', 'avp', 'avq', 'avr', 'avs', 'avt', 'avu', 'avv', 'avw', 'avx', 'avy', 'avz', 'aw', 'awa', 'awb', 'awc', 'awd', 'awe', 'awf', 'awg', 'awh', 'awi', 'awj', 'awk', 'awl', 'awm', 'awn', 'awo', 'awp', 'awq', 'awr', 'aws', 'awt', 'awu', 'awv', 'aww', 'awx', 'awy', 'awz', 'ax', 'axa', 'axb', 'axc', 'axd', 'axe', 'axf', 'axg', 'axh', 'axi', 'axj', 'axk', 'axl', 'axm', 'axn', 'axo', 'axp', 'axq', 'axr', 'axs', 'axt', 'axu', 'axv', 'axw', 'axx', 'axy', 'axz', 'ay', 'aya', 'ayb', 'ayc', 'ayd', 'aye', 'ayf', 'ayg', 'ayh', 'ayi', 'ayj', 'ayk', 'ayl', 'aym', 'ayn', 'ayo', 'ayp', 'ayq', 'ayr', 'ays', 'ayt', 'ayu', 'ayv', 'ayw', 'ayx', 'ayy', 'ayz', 'az', 'aza', 'azb', 'azc', 'azd', 'aze', 'azf', 'azg', 'azh', 'azi', 'azj', 'azk', 'azl', 'azm', 'azn', 'azo', 'azp', 'azq', 'azr', 'azs', 'azt', 'azu', 'azv', 'azw', 'azx', 'azy', 'azz', 'b', 'ba', 'baa', 'bab', 'bac', 'bad', 'bae', 'baf', 'bag', 'bah', 'bai', 'baj', 'bak', 'bal', 'bam', 'ban', 'bao', 'bap', 'baq', 'bar', 'bas', 'bat', 'bau', 'bav', 'baw', 'bax', 'bay', 'baz', 'bb', 'bba', 'bc', 'bca', 'bd', 'bda', 'be', 'bea', 'bf', 'bfa', 'bg', 'bga', 'bh', 'bha', 'bi', 'bia', 'bj', 'bja', 'bk', 'bka', 'bl', 'bla', 'bm', 'bma', 'bn', 'bna', 'bo', 'boa', 'bp', 'bpa', 'bq', 'bqa', 'br', 'bra', 'bs', 'bsa', 'bt', 'bta', 'bu', 'bua', 'bv', 'bva', 'bw', 'bwa', 'bx', 'bxa', 'by', 'bya', 'bz', 'bza', 'c', 'ca', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'can', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cb', 'cba', 'cc', 'cca', 'cd', 'cda', 'ce', 'cea', 'cf', 'cfa', 'cg', 'cga', 'ch', 'cha', 'ci', 'cia', 'cj', 'cja', 'ck', 'cka', 'cl', 'cla', 'cm', 'cma', 'cn', 'cna', 'co', 'coa', 'cp', 'cpa', 'cq', 'cqa', 'cr', 'cra', 'cs', 'csa', 'ct', 'cta', 'cu', 'cua', 'cv', 'cva', 'cw', 'cwa', 'cx', 'cxa', 'cy', 'cya', 'cz', 'cza', 'd', 'da', 'daa', 'dab', 'dac', 'dad', 'dae', 'daf', 'dag', 'dah', 'dai', 'daj', 'dak', 'dal', 'dam', 'dan', 'dao', 'dap', 'daq', 'dar', 'das', 'dat', 'dau', 'dav', 'daw', 'dax', 'day', 'daz', 'db', 'dba', 'dc', 'dca', 'dd', 'dda', 'de', 'dea', 'df', 'dfa', 'dg', 'dga', 'dh', 'dha', 'di', 'dia', 'dj', 'dja', 'dk', 'dka', 'dl', 'dla', 'dm', 'dma', 'dn', 'dna', 'do', 'doa', 'dp', 'dpa', 'dq', 'dqa', 'dr', 'dra', 'ds', 'dsa', 'dt', 'dta', 'du', 'dua', 'dv', 'dva', 'dw', 'dwa', 'dx', 'dxa', 'dy', 'dya', 'dz', 'dza', 'e', 'ea', 'eaa', 'eab', 'eac', 'ead', 'eae', 'eaf', 'eag', 'eah', 'eai', 'eaj', 'eak', 'eal', 'eam', 'ean', 'eao', 'eap', 'eaq', 'ear', 'eas', 'eat', 'eau', 'eav', 'eaw', 'eax', 'eay', 'eaz', 'eb', 'eba', 'ec', 'eca', 'ed', 'eda', 'ee', 'eea', 'ef', 'efa', 'eg', 'ega', 'eh', 'eha', 'ei', 'eia', 'ej', 'eja', 'ek', 'eka', 'el', 'ela', 'em', 'ema', 'en', 'ena', 'eo', 'eoa', 'ep', 'epa', 'eq', 'eqa', 'er', 'era', 'es', 'esa', 'et', 'eta', 'eu', 'eua', 'ev', 'eva', 'ew', 'ewa', 'ex', 'exa', 'ey', 'eya', 'ez', 'eza', 'f', 'fa', 'faa', 'fab', 'fac', 'fad', 'fae', 'faf', 'fag', 'fah', 'fai', 'faj', 'fak', 'fal', 'fam', 'fan', 'fao', 'fap', 'faq', 'far', 'fas', 'fat', 'fau', 'fav', 'faw', 'fax', 'fay', 'faz', 'fb', 'fba', 'fc', 'fca', 'fd', 'fda', 'fe', 'fea', 'ff', 'ffa', 'fg', 'fga', 'fh', 'fha', 'fi', 'fia', 'fj', 'fja', 'fk', 'fka', 'fl', 'fla', 'fm', 'fma', 'fn', 'fna', 'fo', 'foa', 'fp', 'fpa', 'fq', 'fqa', 'fr', 'fra', 'fs', 'fsa', 'ft', 'fta', 'fu', 'fua', 'fv', 'fva', 'fw', 'fwa', 'fx', 'fxa', 'fy', 'fya', 'fz', 'fza', 'g', 'ga', 'gaa', 'gab', 'gac', 'gad', 'gae', 'gaf', 'gag', 'gah', 'gai', 'gaj', 'gak', 'gal', 'gam', 'gan', 'gao', 'gap', 'gaq', 'gar', 'gas', 'gat', 'gau', 'gav', 'gaw', 'gax', 'gay', 'gaz', 'gb', 'gba', 'gc', 'gca', 'gd', 'gda', 'ge', 'gea', 'gf', 'gfa', 'gg', 'gga', 'gh', 'gha', 'gi', 'gia', 'gj', 'gja', 'gk', 'gka', 'gl', 'gla', 'gm', 'gma', 'gn', 'gna', 'go', 'goa', 'gp', 'gpa', 'gq', 'gqa', 'gr', 'gra', 'gs', 'gsa', 'gt', 'gta', 'gu', 'gua', 'gv', 'gva', 'gw', 'gwa', 'gx', 'gxa', 'gy', 'gya', 'gz', 'gza', 'h', 'ha', 'haa', 'hab', 'hac', 'had', 'hae', 'haf', 'hag', 'hah', 'hai', 'haj', 'hak', 'hal', 'ham', 'han', 'hao', 'hap', 'haq', 'har', 'has', 'hat', 'hau', 'hav', 'haw', 'hax', 'hay', 'haz', 'hb', 'hba', 'hc', 'hca', 'hd', 'hda', 'he', 'hea', 'hf', 'hfa', 'hg', 'hga', 'hh', 'hha', 'hi', 'hia', 'hj', 'hja', 'hk', 'hka', 'hl', 'hla', 'hm', 'hma', 'hn', 'hna', 'ho', 'hoa', 'hp', 'hpa', 'hq', 'hqa', 'hr', 'hra', 'hs', 'hsa', 'ht', 'hta', 'hu', 'hua', 'hv', 'hva', 'hw', 'hwa', 'hx', 'hxa', 'hy', 'hya', 'hz', 'hza', 'i', 'ia', 'iaa', 'iab', 'iac', 'iad', 'iae', 'iaf', 'iag', 'iah', 'iai', 'iaj', 'iak', 'ial', 'iam', 'ian', 'iao', 'iap', 'iaq', 'iar', 'ias', 'iat', 'iau', 'iav', 'iaw', 'iax', 'iay', 'iaz', 'ib', 'iba', 'ic', 'ica', 'id', 'ida', 'ie', 'iea', 'if', 'ifa', 'ig', 'iga', 'ih', 'iha', 'ii', 'iia', 'ij', 'ija', 'ik', 'ika', 'il', 'ila', 'im', 'ima', 'in', 'ina', 'io', 'ioa', 'ip', 'ipa', 'iq', 'iqa', 'ir', 'ira', 'is', 'isa', 'it', 'ita', 'iu', 'iua', 'iv', 'iva', 'iw', 'iwa', 'ix', 'ixa', 'iy', 'iya', 'iz', 'iza', 'j', 'ja', 'jaa', 'jab', 'jac', 'jad', 'jae', 'jaf', 'jag', 'jah', 'jai', 'jaj', 'jak', 'jal', 'jam', 'jan', 'jao', 'jap', 'jaq', 'jar', 'jas', 'jat', 'jau', 'jav', 'jaw', 'jax', 'jay', 'jaz', 'jb', 'jba', 'jc', 'jca', 'jd', 'jda', 'je', 'jea', 'jf', 'jfa', 'jg', 'jga', 'jh', 'jha', 'ji', 'jia', 'jj', 'jja', 'jk', 'jka', 'jl', 'jla', 'jm', 'jma', 'jn', 'jna', 'jo', 'joa', 'jp', 'jpa', 'jq', 'jqa', 'jr', 'jra', 'js', 'jsa', 'jt', 'jta', 'ju', 'jua', 'jv', 'jva', 'jw', 'jwa', 'jx', 'jxa', 'jy', 'jya', 'jz', 'jza', 'k', 'ka', 'kaa', 'kab', 'kac', 'kad', 'kae', 'kaf', 'kag', 'kah', 'kai', 'kaj', 'kak', 'kal', 'kam', 'kan', 'kao', 'kap', 'kaq', 'kar', 'kas', 'kat', 'kau', 'kav', 'kaw', 'kax', 'kay', 'kaz', 'kb', 'kba', 'kc', 'kca', 'kd', 'kda', 'ke', 'kea', 'kf', 'kfa', 'kg', 'kga', 'kh', 'kha', 'ki', 'kia', 'kj', 'kja', 'kk', 'kka', 'kl', 'kla', 'km', 'kma', 'kn', 'kna', 'ko', 'koa', 'kp', 'kpa', 'kq', 'kqa', 'kr', 'kra', 'ks', 'ksa', 'kt', 'kta', 'ku', 'kua', 'kv', 'kva', 'kw', 'kwa', 'kx', 'kxa', 'ky', 'kya', 'kz', 'kza', 'l', 'la', 'laa', 'lab', 'lac', 'lad', 'lae', 'laf', 'lag', 'lah', 'lai', 'laj', 'lak', 'lal', 'lam', 'lan', 'lao', 'lap', 'laq', 'lar', 'las', 'lat', 'lau', 'lav', 'law', 'lax', 'lay', 'laz', 'lb', 'lba', 'lc', 'lca', 'ld', 'lda', 'le', 'lea', 'lf', 'lfa', 'lg', 'lga', 'lh', 'lha', 'li', 'lia', 'lj', 'lja', 'lk', 'lka', 'll', 'lla', 'lm', 'lma', 'ln', 'lna', 'lo', 'loa', 'lp', 'lpa', 'lq', 'lqa', 'lr', 'lra', 'ls', 'lsa', 'lt', 'lta', 'lu', 'lua', 'lv', 'lva', 'lw', 'lwa', 'lx', 'lxa', 'ly', 'lya', 'lz', 'lza', 'm', 'ma', 'maa', 'mab', 'mac', 'mad', 'mae', 'maf', 'mag', 'mah', 'mai', 'maj', 'mak', 'mal', 'mam', 'man', 'mao', 'map', 'maq', 'mar', 'mas', 'mat', 'mau', 'mav', 'maw', 'max', 'may', 'maz', 'mb', 'mba', 'mc', 'mca', 'md', 'mda', 'me', 'mea', 'mf', 'mfa', 'mg', 'mga', 'mh', 'mha', 'mi', 'mia', 'mj', 'mja', 'mk', 'mka', 'ml', 'mla', 'mm', 'mma', 'mn', 'mna', 'mo', 'moa', 'mp', 'mpa', 'mq', 'mqa', 'mr', 'mra', 'ms', 'msa', 'mt', 'mta', 'mu', 'mua', 'mv', 'mva', 'mw', 'mwa', 'mx', 'mxa', 'my', 'mya', 'mz', 'mza', 'n', 'na', 'naa', 'nab', 'nac', 'nad', 'nae', 'naf', 'nag', 'nah', 'nai', 'naj', 'nak', 'nal', 'nam', 'nan', 'nao', 'nap', 'naq', 'nar', 'nas', 'nat', 'nau', 'nav', 'naw', 'nax', 'nay', 'naz', 'nb', 'nba', 'nc', 'nca', 'nd', 'nda', 'ne', 'nea', 'nf', 'nfa', 'ng', 'nga', 'nh', 'nha', 'ni', 'nia', 'nj', 'nja', 'nk', 'nka', 'nl', 'nla', 'nm', 'nma', 'nn', 'nna', 'no', 'noa', 'np', 'npa', 'nq', 'nqa', 'nr', 'nra', 'ns', 'nsa', 'nt', 'nta', 'nu', 'nua', 'nv', 'nva', 'nw', 'nwa', 'nx', 'nxa', 'ny', 'nya', 'nz', 'nza', 'o', 'oa', 'oaa', 'oab', 'oac', 'oad', 'oae', 'oaf', 'oag', 'oah', 'oai', 'oaj', 'oak', 'oal', 'oam', 'oan', 'oao', 'oap', 'oaq', 'oar', 'oas', 'oat', 'oau', 'oav', 'oaw', 'oax', 'oay', 'oaz', 'ob', 'oba', 'oc', 'oca', 'od', 'oda', 'oe', 'oea', 'of', 'ofa', 'og', 'oga', 'oh', 'oha', 'oi', 'oia', 'oj', 'oja', 'ok', 'oka', 'ol', 'ola', 'om', 'oma', 'on', 'ona', 'oo', 'ooa', 'op', 'opa', 'oq', 'oqa', 'or', 'ora', 'os', 'osa', 'ot', 'ota', 'ou', 'oua', 'ov', 'ova', 'ow', 'owa', 'ox', 'oxa', 'oy', 'oya', 'oz', 'oza', 'p', 'pa', 'paa', 'pab', 'pac', 'pad', 'pae', 'paf', 'pag', 'pah', 'pai', 'paj', 'pak', 'pal', 'pam', 'pan', 'pao', 'pap', 'paq', 'par', 'pas', 'pat', 'pau', 'pav', 'paw', 'pax', 'pay', 'paz', 'pb', 'pba', 'pc', 'pca', 'pd', 'pda', 'pe', 'pea', 'pf', 'pfa', 'pg', 'pga', 'ph', 'pha', 'pi', 'pia', 'pj', 'pja', 'pk', 'pka', 'pl', 'pla', 'pm', 'pma', 'pn', 'pna', 'po', 'poa', 'pp', 'ppa', 'pq', 'pqa', 'pr', 'pra', 'ps', 'psa', 'pt', 'pta', 'pu', 'pua', 'pv', 'pva', 'pw', 'pwa', 'px', 'pxa', 'py', 'pya', 'pz', 'pza', 'q', 'qa', 'qaa', 'qab', 'qac', 'qad', 'qae', 'qaf', 'qag', 'qah', 'qai', 'qaj', 'qak', 'qal', 'qam', 'qan', 'qao', 'qap', 'qaq', 'qar', 'qas', 'qat', 'qau', 'qav', 'qaw', 'qax', 'qay', 'qaz', 'qb', 'qba', 'qc', 'qca', 'qd', 'qda', 'qe', 'qea', 'qf', 'qfa', 'qg', 'qga', 'qh', 'qha', 'qi', 'qia', 'qj', 'qja', 'qk', 'qka', 'ql', 'qla', 'qm', 'qma', 'qn', 'qna', 'qo', 'qoa', 'qp', 'qpa', 'qq', 'qqa', 'qr', 'qra', 'qs', 'qsa', 'qt', 'qta', 'qu', 'qua', 'qv', 'qva', 'qw', 'qwa', 'qx', 'qxa', 'qy', 'qya', 'qz', 'qza', 'r', 'ra', 'raa', 'rab', 'rac', 'rad', 'rae', 'raf', 'rag', 'rah', 'rai', 'raj', 'rak', 'ral', 'ram', 'ran', 'rao', 'rap', 'raq', 'rar', 'ras', 'rat', 'rau', 'rav', 'raw', 'rax', 'ray', 'raz', 'rb', 'rba', 'rc', 'rca', 'rd', 'rda', 're', 'rea', 'rf', 'rfa', 'rg', 'rga', 'rh', 'rha', 'ri', 'ria', 'rj', 'rja', 'rk', 'rka', 'rl', 'rla', 'rm', 'rma', 'rn', 'rna', 'ro', 'roa', 'rp', 'rpa', 'rq', 'rqa', 'rr', 'rra', 'rs', 'rsa', 'rt', 'rta', 'ru', 'rua', 'rv', 'rva', 'rw', 'rwa', 'rx', 'rxa', 'ry', 'rya', 'rz', 'rza', 's', 'sa', 'saa', 'sab', 'sac', 'sad', 'sae', 'saf', 'sag', 'sah', 'sai', 'saj', 'sak', 'sal', 'sam', 'san', 'sao', 'sap', 'saq', 'sar', 'sas', 'sat', 'sau', 'sav', 'saw', 'sax', 'say', 'saz', 'sb', 'sba', 'sc', 'sca', 'sd', 'sda', 'se', 'sea', 'sf', 'sfa', 'sg', 'sga', 'sh', 'sha', 'si', 'sia', 'sj', 'sja', 'sk', 'ska', 'sl', 'sla', 'sm', 'sma', 'sn', 'sna', 'so', 'soa', 'sp', 'spa', 'sq', 'sqa', 'sr', 'sra', 'ss', 'ssa', 'st', 'sta', 'su', 'sua', 'sv', 'sva', 'sw', 'swa', 'sx', 'sxa', 'sy', 'sya', 'sz', 'sza', 't', 'ta', 'taa', 'tab', 'tac', 'tad', 'tae', 'taf', 'tag', 'tah', 'tai', 'taj', 'tak', 'tal', 'tam', 'tan', 'tao', 'tap', 'taq', 'tar', 'tas', 'tat', 'tau', 'tav', 'taw', 'tax', 'tay', 'taz', 'tb', 'tba', 'tc', 'tca', 'td', 'tda', 'te', 'tea', 'tf', 'tfa', 'tg', 'tga', 'th', 'tha', 'ti', 'tia', 'tj', 'tja', 'tk', 'tka', 'tl', 'tla', 'tm', 'tma', 'tn', 'tna', 'to', 'toa', 'tp', 'tpa', 'tq', 'tqa', 'tr', 'tra', 'ts', 'tsa', 'tt', 'tta', 'tu', 'tua', 'tv', 'tva', 'tw', 'twa', 'tx', 'txa', 'ty', 'tya', 'tz', 'tza', 'u', 'ua', 'uaa', 'uab', 'uac', 'uad', 'uae', 'uaf', 'uag', 'uah', 'uai', 'uaj', 'uak', 'ual', 'uam', 'uan', 'uao', 'uap', 'uaq', 'uar', 'uas', 'uat', 'uau', 'uav', 'uaw', 'uax', 'uay', 'uaz', 'ub', 'uba', 'uc', 'uca', 'ud', 'uda', 'ue', 'uea', 'uf', 'ufa', 'ug', 'uga', 'uh', 'uha', 'ui', 'uia', 'uj', 'uja', 'uk', 'uka', 'ul', 'ula', 'um', 'uma', 'un', 'una', 'uo', 'uoa', 'up', 'upa', 'uq', 'uqa', 'ur', 'ura', 'us', 'usa', 'ut', 'uta', 'uu', 'uua', 'uv', 'uva', 'uw', 'uwa', 'ux', 'uxa', 'uy', 'uya', 'uz', 'uza', 'v', 'va', 'vaa', 'vab', 'vac', 'vad', 'vae', 'vaf', 'vag', 'vah', 'vai', 'vaj', 'vak', 'val', 'vam', 'van', 'vao', 'vap', 'vaq', 'var', 'vas', 'vat', 'vau', 'vav', 'vaw', 'vax', 'vay', 'vaz', 'vb', 'vba', 'vc', 'vca', 'vd', 'vda', 've', 'vea', 'vf', 'vfa', 'vg', 'vga', 'vh', 'vha', 'vi', 'via', 'vj', 'vja', 'vk', 'vka', 'vl', 'vla', 'vm', 'vma', 'vn', 'vna', 'vo', 'voa', 'vp', 'vpa', 'vq', 'vqa', 'vr', 'vra', 'vs', 'vsa', 'vt', 'vta', 'vu', 'vua', 'vv', 'vva', 'vw', 'vwa', 'vx', 'vxa', 'vy', 'vya', 'vz', 'vza', 'w', 'wa', 'waa', 'wab', 'wac', 'wad', 'wae', 'waf', 'wag', 'wah', 'wai', 'waj', 'wak', 'wal', 'wam', 'wan', 'wao', 'wap', 'waq', 'war', 'was', 'wat', 'wau', 'wav', 'waw', 'wax', 'way', 'waz', 'wb', 'wba', 'wc', 'wca', 'wd', 'wda', 'we', 'wea', 'wf', 'wfa', 'wg', 'wga', 'wh', 'wha', 'wi', 'wia', 'wj', 'wja', 'wk', 'wka', 'wl', 'wla', 'wm', 'wma', 'wn', 'wna', 'wo', 'woa', 'wp', 'wpa', 'wq', 'wqa', 'wr', 'wra', 'ws', 'wsa', 'wt', 'wta', 'wu', 'wua', 'wv', 'wva', 'ww', 'wwa', 'wx', 'wxa', 'wy', 'wya', 'wz', 'wza', 'x', 'xa', 'xaa', 'xab', 'xac', 'xad', 'xae', 'xaf', 'xag', 'xah', 'xai', 'xaj', 'xak', 'xal', 'xam', 'xan', 'xao', 'xap', 'xaq', 'xar', 'xas', 'xat', 'xau', 'xav', 'xaw', 'xax', 'xay', 'xaz', 'xb', 'xba', 'xc', 'xca', 'xd', 'xda', 'xe', 'xea', 'xf', 'xfa', 'xg', 'xga', 'xh', 'xha', 'xi', 'xia', 'xj', 'xja', 'xk', 'xka', 'xl', 'xla', 'xm', 'xma', 'xn', 'xna', 'xo', 'xoa', 'xp', 'xpa', 'xq', 'xqa', 'xr', 'xra', 'xs', 'xsa', 'xt', 'xta', 'xu', 'xua', 'xv', 'xva', 'xw', 'xwa', 'xx', 'xxa', 'xy', 'xya', 'xz', 'xza', 'y', 'ya', 'yaa', 'yab', 'yac', 'yad', 'yae', 'yaf', 'yag', 'yah', 'yai', 'yaj', 'yak', 'yal', 'yam', 'yan', 'yao', 'yap', 'yaq', 'yar', 'yas', 'yat', 'yau', 'yav', 'yaw', 'yax', 'yay', 'yaz', 'yb', 'yba', 'yc', 'yca', 'yd', 'yda', 'ye', 'yea', 'yf', 'yfa', 'yg', 'yga', 'yh', 'yha', 'yi', 'yia', 'yj', 'yja', 'yk', 'yka', 'yl', 'yla', 'ym', 'yma', 'yn', 'yna', 'yo', 'yoa', 'yp', 'ypa', 'yq', 'yqa', 'yr', 'yra', 'ys', 'ysa', 'yt', 'yta', 'yu', 'yua', 'yv', 'yva', 'yw', 'ywa', 'yx', 'yxa', 'yy', 'yya', 'yz', 'yza', 'z', 'za', 'zaa', 'zab', 'zac', 'zad', 'zae', 'zaf', 'zag', 'zah', 'zai', 'zaj', 'zak', 'zal', 'zam', 'zan', 'zao', 'zap', 'zaq', 'zar', 'zas', 'zat', 'zau', 'zav', 'zaw', 'zax', 'zay', 'zaz', 'zb', 'zba', 'zc', 'zca', 'zd', 'zda', 'ze', 'zea', 'zf', 'zfa', 'zg', 'zga', 'zh', 'zha', 'zi', 'zia', 'zj', 'zja', 'zk', 'zka', 'zl', 'zla', 'zm', 'zma', 'zn', 'zna', 'zo', 'zoa', 'zp', 'zpa', 'zq', 'zqa', 'zr', 'zra', 'zs', 'zsa', 'zt', 'zta', 'zu', 'zua', 'zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n"
     ]
    }
   ],
   "source": [
    "# let's check \n",
    "word = 'a'\n",
    "editing = edit_two_letter(word = word)\n",
    "final_words = sorted( list(editing))\n",
    "print(f'word:{word}\\nEdit Two Letters:\\n{final_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302b5c7",
   "metadata": {
    "papermill": {
     "duration": 0.010316,
     "end_time": "2023-07-29T15:19:55.787169",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.776853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"background: #ea97ad;text-align:center\">Make Suggestions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9ef58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.810280Z",
     "iopub.status.busy": "2023-07-29T15:19:55.809845Z",
     "iopub.status.idle": "2023-07-29T15:19:55.835603Z",
     "shell.execute_reply": "2023-07-29T15:19:55.834331Z"
    },
    "papermill": {
     "duration": 0.040733,
     "end_time": "2023-07-29T15:19:55.838443",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.797710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_suggestions(word, proba ,vocab ,n=2 ,verbos=False):\n",
    "    suggestions = []\n",
    "    top_n_suggestions=[]\n",
    "    \n",
    "    suggestions = list( (word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letter(word).intersection(vocab) )\n",
    "    top_sug = [[s,proba[s]] for s in list(suggestions)  ]\n",
    "    top_proba = max([proba[s] for s in suggestions])\n",
    "    top_n_suggestions = top_sug[:n]\n",
    "    if verbos:\n",
    "        print(f'word: {word}\\nSuggestions:\\n{suggestions}')\n",
    "        print(f'top probability :{top_proba}')\n",
    "    return top_n_suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcbb0216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.862313Z",
     "iopub.status.busy": "2023-07-29T15:19:55.861846Z",
     "iopub.status.idle": "2023-07-29T15:19:55.869106Z",
     "shell.execute_reply": "2023-07-29T15:19:55.867778Z"
    },
    "papermill": {
     "duration": 0.022652,
     "end_time": "2023-07-29T15:19:55.872027",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.849375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: dys\n",
      "Suggestions:\n",
      "['dis', 'dye', 'days', 'dy', 'des']\n",
      "top probability :0.00022487723209482286\n",
      "top 2 : \n",
      "[['dis', 5.379838088392892e-06], ['dye', 5.379838088392892e-06]]\n"
     ]
    }
   ],
   "source": [
    "# let's show result \n",
    "word  = 'dys'\n",
    "proba = words_proba\n",
    "vocab = vocab\n",
    "n     = 2\n",
    "verbos= True\n",
    "\n",
    "get_items = make_suggestions(word, proba, vocab ,n,verbos)\n",
    "print(f'top 2 : \\n{get_items}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575856af",
   "metadata": {
    "papermill": {
     "duration": 0.011353,
     "end_time": "2023-07-29T15:19:55.894147",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.882794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"background: #ea97ad;text-align:center\">Minimum Edit Distance</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d765c95",
   "metadata": {
    "papermill": {
     "duration": 0.010699,
     "end_time": "2023-07-29T15:19:55.915788",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.905089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"background: #ea97ad;text-align:center\">Dynamic Programming</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94241a1",
   "metadata": {
    "papermill": {
     "duration": 0.010728,
     "end_time": "2023-07-29T15:19:55.937885",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.927157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dynamic Programming breaks a problem down into subproblems which can be combined to form the final solution. Here, given a string source[0..i] and a string target[0..j], we will compute all the combinations of substrings[i, j] and calculate their edit distance. To do this efficiently, we will use a table to maintain the previously computed substrings and use those to calculate larger substrings. We can update each element in the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574b096b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:55.961427Z",
     "iopub.status.busy": "2023-07-29T15:19:55.960979Z",
     "iopub.status.idle": "2023-07-29T15:19:55.974392Z",
     "shell.execute_reply": "2023-07-29T15:19:55.973053Z"
    },
    "papermill": {
     "duration": 0.028389,
     "end_time": "2023-07-29T15:19:55.977240",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.948851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: a string corresponding to the string we are starting with\n",
    "        target: a string corresponding to the string we want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    '''\n",
    "    # use deletion and insert cost as  1\n",
    "    m = len(source) \n",
    "    n = len(target) \n",
    "    \n",
    "    #initialize cost matrix with zeros and dimensions (m+1,n+1) \n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "    \n",
    "    # Fill in column 0, from row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1): \n",
    "        D[row,0] = D[row-1, 0]+del_cost\n",
    "        \n",
    "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
    "    for col in range(1,n+1): \n",
    "        D[0,col] = D[0, col-1]+ins_cost\n",
    "        \n",
    "    # Loop through row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1): \n",
    "        \n",
    "        # Loop through column 1 to column n, both inclusive\n",
    "        for col in range(1,n+1):\n",
    "            \n",
    "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
    "            r_cost = rep_cost\n",
    "            \n",
    "            # Check to see if source character at the previous row\n",
    "            # matches the target character at the previous column, \n",
    "            # (source) 'TAY' (target) 'SAY': Check if 'T'=='S'\n",
    "            if source[row-1] == target[col-1]:\n",
    "                # Update the replacement cost to 0 if source and target are the same\n",
    "                r_cost = 0\n",
    "                \n",
    "            # Update the cost at row, col based on previous entries in the cost matrix\n",
    "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
    "\n",
    "            cost_del = D[row-1, col] + del_cost\n",
    "            cost_ins = D[row, col-1] + ins_cost\n",
    "            cost_replace = D[row-1, col-1] + r_cost\n",
    "            \n",
    "            D[row,col] = min(cost_del, cost_ins, cost_replace)\n",
    "          \n",
    "    # Set the minimum edit distance with the cost found at row m, column n\n",
    "    med = D[m, n]\n",
    "    \n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c43a4af1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T15:19:56.001264Z",
     "iopub.status.busy": "2023-07-29T15:19:56.000562Z",
     "iopub.status.idle": "2023-07-29T15:19:56.025235Z",
     "shell.execute_reply": "2023-07-29T15:19:56.023722Z"
    },
    "papermill": {
     "duration": 0.039452,
     "end_time": "2023-07-29T15:19:56.027876",
     "exception": false,
     "start_time": "2023-07-29T15:19:55.988424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  3 \n",
      "\n",
      "   #  n  e  a  r\n",
      "#  0  1  2  3  4\n",
      "e  1  2  1  2  3\n",
      "e  2  3  2  3  4\n",
      "r  3  4  3  4  3\n"
     ]
    }
   ],
   "source": [
    "source =  'eer'\n",
    "target = 'near'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list('#' + source)\n",
    "cols = list('#' + target)\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.111724,
   "end_time": "2023-07-29T15:19:57.163637",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-29T15:19:39.051913",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
